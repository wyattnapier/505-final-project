# -*- coding: utf-8 -*-
"""CS505_Ranking_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gRa7jt8viGR28eDN5x6QurMNf0BYtfuc
"""

# File for analyzing the results of our survey
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv("/content/Survey_Rankings.csv")
df = df[df['sheet_name'] != 14]

# Splitting up the df into our control samples and other(for later visualizations)

control_ids = ['12mb606', '12z7zbp', '13t5qyw', '164nzl5', '17c64lr']

df_control = df[df['id'].isin(control_ids)].copy()


df_other = df[~df['id'].isin(control_ids)].copy()

# Full df ranking proportions
proportions_all = df['Ranking'].value_counts(normalize=True)
print((proportions_all * 100).round(2).astype(str) + '%')

#Proportions of control:

proportions_control = df_control['Ranking'].value_counts(normalize=True)
print((proportions_control * 100).round(2).astype(str) + '%')

# Proportions of the randomly selected ones

proportions_random = df_other['Ranking'].value_counts(normalize=True)
print((proportions_random * 100).round(2).astype(str) + '%')

import matplotlib.pyplot as plt
from statsmodels.stats.proportion import proportion_confint

# counts
counts = df['Ranking'].value_counts().sort_index()
n   = counts.sum()
props = counts / n

# 95% Wilson CIs
cis_low, cis_upp = proportion_confint(counts, n, method='wilson')

# bar + errorbars
plt.bar(props.index.astype(str), props.values)
plt.errorbar(props.index.astype(str), props.values,
             yerr=[props.values - cis_low, cis_upp - props.values],
             fmt='none', capsize=5)
plt.ylim(0,1)
plt.ylabel("Proportion")
plt.xlabel("Ranking")
plt.title("Proportion of Rankings with 95% Wilson CIs")
plt.show()

#Pairwise agreement, this calculates the "Raw" agreement in rankings with our control samples.

n_raters   = df_control['sheet_name'].nunique()
total_pairs = n_raters*(n_raters-1)

P_i = []
for _, grp in df_control.groupby('id'):
    counts = grp['Ranking'].value_counts()
    agree_pairs = sum(counts[c]*(counts[c]-1) for c in counts.index)
    P_i.append(agree_pairs/total_pairs)

P_o = np.mean(P_i)

print(f"Mean pairwise agreement: {P_o:.2%}")

# Using a chance corrected metric (Bennet, Alpert and Goldstein's S agreement index)

# Expected agreement under uniform chance
n_categories = df_control['Ranking'].nunique()  # should be 2
P_e = 1 / n_categories

# 6) Bennett et al.’s S
S = (P_o - P_e) / (1 - P_e)

print(f"P_o (observed agreement) = {P_o:.3f}")
print(f"P_e (chance level)        = {P_e:.3f}")
print(f"Bennett, Alpert & Goldstein’s S = {S:.3f}")