# -*- coding: utf-8 -*-
"""Zeroshot_Annotation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_bgNqTyqYknQgjqGPPe_zCmOMwf1_hIv

### Running the code on the combined dataset
"""

import json
import gc
import torch
import pandas as pd
from tqdm.auto import tqdm
from transformers import pipeline

def write_jsonl(path, item):
    with open(path, 'a') as f:
        f.write(json.dumps(item, default=str) + '\n') #fixes the timestamp thing

candidate_labels = [
    'hopelessness','humiliation','anger','guilt',
    'substance abuse','loneliness','suicide intent'
]

def process_dataset(in_path, out_path, batch_size=16, threshold=0.50):
    # clear out_path
    open(out_path, 'w').close()

    # set device
    device = 0 if torch.cuda.is_available() else -1

    # zero-shot classifier
    classifier = pipeline(
        "zero-shot-classification",
        model="MoritzLaurer/deberta-v3-large-zeroshot-v2.0",
        device=device,
        torch_dtype=torch.float16
    )

    # read as dataset for batch processing
    reader = pd.read_json(in_path, lines=True, chunksize=batch_size)

    for batch_df in tqdm(reader, desc="Batches"):
        # fill missing text
        texts = batch_df['text'].fillna('').tolist()

        # run classifier
        outputs = classifier(
            texts,
            candidate_labels,
            multi_label=True,
            batch_size=len(texts),
            truncation=True,
            max_length=256
        )

        # write out results
        for record, out in zip(batch_df.to_dict(orient='records'), outputs):
            filt = [lbl for lbl, sc in zip(out['labels'], out['scores']) if sc > threshold]
            write_jsonl(out_path, {**record, 'candidates': filt})

if __name__ == "__main__":
    process_dataset(
        '/content/final_dataset_nolabels.json',
        '/content/roberta_zeroshot.json',
        batch_size=16,
        threshold=0.50
    )

